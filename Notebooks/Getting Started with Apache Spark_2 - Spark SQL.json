{"paragraphs":[{"text":"//For this set of demos, we want to read in a ratings data set with approximately 20 million ratings.\nval ratings = spark.read.format(\"CSV\").option(\"header\",\"true\").load(\"hdfs:///user/kevin/Movies/ml-20m/ratings.csv\")\n\n//We will use Spark SQL to solve a series of exercises.","user":"admin","dateUpdated":"2018-11-04T11:54:21-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539657297593_-2059314797","id":"20181015-223457_590986072","dateCreated":"2018-10-15T22:34:57-0400","dateStarted":"2018-11-04T11:54:21-0500","dateFinished":"2018-11-04T11:54:22-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5898"},{"text":"//Exercise 1:  Ensure that the MovieLens data set really has 20 million ratings\r\nratings.count()","user":"admin","dateUpdated":"2018-11-04T11:54:50-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539655769964_-11083508","id":"20181015-220929_1204080512","dateCreated":"2018-10-15T22:09:29-0400","dateStarted":"2018-11-04T11:54:50-0500","dateFinished":"2018-11-04T11:54:59-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5899"},{"text":"//Exercise 2:  Find the number of votes by rating\r\nval results = ratings.groupBy(\"rating\").count()\r\nresults.orderBy(\"rating\").show(10)","user":"admin","dateUpdated":"2018-11-04T11:55:14-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539657052290_-1713177060","id":"20181015-223052_1905644951","dateCreated":"2018-10-15T22:30:52-0400","dateStarted":"2018-11-04T11:55:14-0500","dateFinished":"2018-11-04T11:55:25-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5900"},{"text":"//Exercise 3:  Find the movies with most ratings\r\nval ratingsPerMovie = ratings.groupBy(\"movieId\").count()\r\nratingsPerMovie.orderBy(desc(\"count\")).show(10)","user":"admin","dateUpdated":"2018-11-04T11:56:15-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539657342593_-163394811","id":"20181015-223542_2104574449","dateCreated":"2018-10-15T22:35:42-0400","dateStarted":"2018-11-04T11:56:16-0500","dateFinished":"2018-11-04T11:56:27-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5901"},{"text":"//Exercise 3, take 2:\r\n//But we probably want to know about the specific movies.  So let's read in the movie data set and try again.\r\nval movies = spark.read.format(\"CSV\").option(\"header\",\"true\").load(\"hdfs:///user/kevin/Movies/ml-20m/movies.csv\")\r\nratingsPerMovie.orderBy(desc(\"count\")).as(\"ratingsPerMovie\").\r\n                join(movies.as(\"movies\"), col(\"ratingsPerMovie.movieId\") === col(\"movies.movieId\"), \"inner\").\r\n                select($\"title\", $\"count\").\r\n                show(10, false)\r\n","user":"admin","dateUpdated":"2018-11-04T11:57:10-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539657376282_-1867570283","id":"20181015-223616_2128086946","dateCreated":"2018-10-15T22:36:16-0400","dateStarted":"2018-11-04T11:57:10-0500","dateFinished":"2018-11-04T11:57:22-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5902"},{"text":"//Exercise 3, take 3:\r\n//Now let's do this as a SQL statement.  We'll create temporary Spark views from the DataFrames above and then write a SQL query to get the same results.\r\nratingsPerMovie.createOrReplaceTempView(\"RatingsPerMovie\")\r\nmovies.createOrReplaceTempView(\"Movie\")\r\nspark.sql(\"SELECT m.title, rpm.count FROM RatingsPerMovie rpm INNER JOIN Movie m ON rpm.movieId = m.movieId ORDER BY rpm.count DESC LIMIT 10\").show(10, false)\r\n","user":"admin","dateUpdated":"2018-11-04T11:59:32-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539657418470_-833303943","id":"20181015-223658_1320981490","dateCreated":"2018-10-15T22:36:58-0400","dateStarted":"2018-11-04T11:59:32-0500","dateFinished":"2018-11-04T11:59:43-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5903"},{"text":"//Exercise 4:  Top-Rated Movies, min 1000 reviews.\r\n//Note that I use three quotation marks to set off a multi-line string.\r\nratings.createOrReplaceTempView(\"MovieRating\")\r\nspark.sql(\"\"\"\r\n\tSELECT\r\n\t\tm.title,\r\n\t\tCOUNT(*) AS numreviews,\r\n\t\tCAST(SUM(mr.rating) / COUNT(mr.rating) AS DECIMAL(3,2)) AS avgrating\r\n\tFROM MovieRating mr\r\n\t\tINNER JOIN Movie m\r\n\t\t\tON mr.movieId = m.movieId\r\n\tGROUP BY\r\n\t\tm.title\r\n\tHAVING\r\n\t\tCOUNT(*) > 1000\r\n\tORDER BY\r\n\t\tavgrating DESC\r\n\"\"\").show(10, false)","user":"admin","dateUpdated":"2018-11-04T12:00:26-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539657492545_1241520993","id":"20181015-223812_2055286726","dateCreated":"2018-10-15T22:38:12-0400","dateStarted":"2018-11-04T12:00:26-0500","dateFinished":"2018-11-04T12:00:42-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5904"},{"text":"//Exercise 5:  Lowest-Rated Movies, min 1000 reviews.  The movies everyone loves to hate.\r\nspark.sql(\"\"\"\r\n\tSELECT\r\n\t\tm.title,\r\n\t\tCOUNT(*) AS numreviews,\r\n\t\tCAST(SUM(mr.rating) / COUNT(mr.rating) AS DECIMAL(3,2)) AS avgrating \r\n\tFROM MovieRating mr\r\n\t\tINNER JOIN Movie m\r\n\t\t\tON mr.movieId = m.movieId\r\n\tGROUP BY\r\n\t\tm.title\r\n\tHAVING\r\n\t\tCOUNT(*) > 1000\r\n\tORDER BY\r\n\t\tavgrating ASC\r\n\"\"\").show(10, false)","user":"admin","dateUpdated":"2018-11-04T12:01:08-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539657528654_898187057","id":"20181015-223848_263669121","dateCreated":"2018-10-15T22:38:48-0400","dateStarted":"2018-11-04T12:01:08-0500","dateFinished":"2018-11-04T12:01:23-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5905"},{"text":"//Exercise 6:  Movies both highly-rated and beloved.\r\n//The solution here is to take the top 100 most-rated movies, the top 100 highest-rated movies (with a minimum of 10 ratings), and see how much overlap there is.\r\nval topRatedMovies = spark.sql(\"\"\"\r\n\tSELECT\r\n\t\tm.movieId,\r\n\t\tm.title,\r\n\t\trpm.count\r\n\tFROM RatingsPerMovie rpm\r\n\t\tINNER JOIN Movie m\r\n\t\t\tON rpm.movieId = m.movieId\r\n\tORDER BY\r\n\t\trpm.count DESC\r\n\tLIMIT 100\r\n\"\"\")\r\nval highestRatedMovies = spark.sql(\"\"\"\r\n\tSELECT\r\n\t\tm.movieId,\r\n\t\tm.title,\r\n\t\tCOUNT(*) AS numreviews,\r\n\t\tCAST(SUM(mr.rating) / COUNT(mr.rating) AS DECIMAL(3,2)) AS avgrating\r\n\tFROM MovieRating mr\r\n\t\tINNER JOIN Movie m\r\n\t\t\tON mr.movieId = m.movieId\r\n\tGROUP BY\r\n\t\tm.movieId,\r\n\t\tm.title\r\n\tHAVING\r\n\t\tCOUNT(*) >= 10\r\n\tORDER BY\r\n\t\tavgrating DESC\r\n\tLIMIT 100\r\n\"\"\")\r\nval highlyRatedAndBelovedMovies = topRatedMovies.as(\"TopRatedMovies\").\r\n                                                 join(highestRatedMovies.as(\"HighestRatedMovies\"), col(\"TopRatedMovies.movieId\") === col(\"HighestRatedMovies.movieId\"), \"inner\")\r\nhighlyRatedAndBelovedMovies.select($\"TopRatedMovies.title\", $\"TopRatedMovies.count\", $\"HighestRatedMovies.avgrating\").\r\n                            orderBy(desc(\"avgrating\")).show(100, false)\r\nhighlyRatedAndBelovedMovies.count()\r\n","user":"admin","dateUpdated":"2018-11-04T12:02:59-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539657554868_1087514164","id":"20181015-223914_31517034","dateCreated":"2018-10-15T22:39:14-0400","dateStarted":"2018-11-04T12:02:59-0500","dateFinished":"2018-11-04T12:03:57-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5906"},{"text":"//Exercise 6, take 2:\n//Another way to do this using window functions.  Note the partition warning!\n//Because we are using window functions without partitions, the likelihood of expensive shuffling is high.\n//We don't care about it here because I'm working on a single-node cluster, but this can be significant in real scenarios.\nspark.sql(\"\"\"\nWITH reviews AS\n(\n\tSELECT\n\t    m.movieId,\n\t\tm.title,\n\t\tCOUNT(*) AS numreviews,\n\t\tCAST(SUM(mr.rating) / COUNT(mr.rating) AS DECIMAL(3,2)) AS avgrating\n\tFROM MovieRating mr\n\t\tINNER JOIN Movie m\n\t\t\tON mr.movieId = m.movieId\n\tGROUP BY\n\t    m.movieId,\n\t\tm.title\n\tHAVING\n\t\tCOUNT(*) > 10\n),\nrankings AS\n(\n\tSELECT\n\t\tr.title,\n\t\tr.numreviews,\n\t\tRANK() OVER (ORDER BY r.numreviews DESC) AS reviewrank,\n\t\tr.avgrating,\n\t\tRANK() OVER (ORDER BY r.avgrating DESC) as avgratingrank\n\tFROM reviews r\n)\nSELECT\n\tr.title,\n\tr.numreviews,\n\tr.reviewrank,\n\tr.avgrating,\n\tr.avgratingrank\nFROM rankings r\nWHERE\n\tr.reviewrank <= 100\n\tAND r.avgratingrank <= 100\nORDER BY\n\tavgrating DESC\n\"\"\").show(100, false)\n\n//As a bonus, note that the result set is a little different from that above--this is because RANK is pulling in more than 100 total films.","user":"admin","dateUpdated":"2018-11-04T12:05:24-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539657675292_-2091865212","id":"20181015-224115_1733169027","dateCreated":"2018-10-15T22:41:15-0400","dateStarted":"2018-11-04T12:05:24-0500","dateFinished":"2018-11-04T12:05:41-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5907"},{"text":"//Exercise 7:  Find the most common movie genres\r\n//To understand this solution, we need to understand a few things.  First, Genres are stored in a pipe-delimited string.\r\n//Build up some basic info.  First, genres:\r\nspark.sql(\"SELECT Title, Genres FROM Movie\").show(50, false)\r\n","user":"admin","dateUpdated":"2018-11-04T12:06:40-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539657862177_-882736813","id":"20181015-224422_304185669","dateCreated":"2018-10-15T22:44:22-0400","dateStarted":"2018-11-04T12:06:40-0500","dateFinished":"2018-11-04T12:06:41-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5908"},{"text":"//Use split() to turn the delimited string into an array. Note that | is a special character so needs offset by \\\\ but for single-quote operations you need \\\\\\\\:\r\nspark.sql(\"SELECT Title, split(Genres, '\\\\\\\\|') AS Genres FROM Movie\").show(50, false)\r\n","user":"admin","dateUpdated":"2018-11-04T12:07:00-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539658076912_899125644","id":"20181015-224756_288908755","dateCreated":"2018-10-15T22:47:56-0400","dateStarted":"2018-11-04T12:07:00-0500","dateFinished":"2018-11-04T12:07:00-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5909"},{"text":"//Use explode() to put each genre on its own line along with the Title.\r\nspark.sql(\"SELECT Title, explode(split(Genres, '\\\\\\\\|')) AS Genre FROM Movie\").show(50, false)","user":"admin","dateUpdated":"2018-11-04T12:07:48-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539658109883_187202261","id":"20181015-224829_352162448","dateCreated":"2018-10-15T22:48:29-0400","dateStarted":"2018-11-04T12:07:48-0500","dateFinished":"2018-11-04T12:07:48-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5910"},{"text":"//Now we can solve the exercise question by combining these together.\r\n//Note that with the multi-line string, I just need \\\\ instead of \\\\\\\\!\r\nspark.sql(\"\"\"\r\n\tWITH genres AS\r\n\t(\r\n\t\tSELECT\r\n\t\t\tTitle, \r\n\t\t\texplode(split(Genres, '\\\\|')) AS Genre\r\n\t\tFROM Movie\r\n\t)\r\n\tSELECT\r\n\t\tGenre,\r\n\t\tCOUNT(*) AS NumberOfOccurrences\r\n\tFROM genres\r\n\tGROUP BY\r\n\t\tGenre\r\n\tORDER BY\r\n\t\tNumberOfOccurrences DESC\r\n\"\"\").show(50, false)","user":"admin","dateUpdated":"2018-11-04T12:08:26-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539658027959_-1542567497","id":"20181015-224707_636838620","dateCreated":"2018-10-15T22:47:07-0400","dateStarted":"2018-11-04T12:08:26-0500","dateFinished":"2018-11-04T12:08:26-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5911"},{"user":"admin","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1539658158431_1774953703","id":"20181015-224918_810426413","dateCreated":"2018-10-15T22:49:18-0400","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:5912"}],"name":"Getting Started with Apache Spark/2 - Spark SQL","id":"2DSHN7BTM","angularObjects":{"2C4U48MY3_spark2:shared_process":[],"2CKAY1A8Y:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}